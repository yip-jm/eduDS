FATAL:   Image file already exists: "ollama_latest.sif" - will not overwrite
INFO:    Environment variable SINGULARITYENV_OLLAMA_HOST is set, but APPTAINERENV_OLLAMA_HOST is preferred
2025/06/18 23:11:58 config.go:45: WARN invalid port, using default port="" default=11434
2025/06/18 23:11:58 config.go:45: WARN invalid port, using default port="" default=11434
time=2025-06-18T23:11:58.585+02:00 level=WARN source=config.go:45 msg="invalid port, using default" port="" default=11434
time=2025-06-18T23:11:58.586+02:00 level=INFO source=routes.go:1234 msg="server config" env="map[CUDA_VISIBLE_DEVICES:0 GPU_DEVICE_ORDINAL:0 HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY:cublas OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:4 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/jye/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES:0 http_proxy: https_proxy: no_proxy:]"
time=2025-06-18T23:11:58.605+02:00 level=INFO source=images.go:479 msg="total blobs: 38"
time=2025-06-18T23:11:58.606+02:00 level=INFO source=images.go:486 msg="total unused blobs removed: 0"
time=2025-06-18T23:11:58.607+02:00 level=INFO source=routes.go:1287 msg="Listening on [::]:11434 (version 0.9.0)"
time=2025-06-18T23:11:58.608+02:00 level=INFO source=gpu.go:217 msg="looking for compatible GPUs"
time=2025-06-18T23:11:59.509+02:00 level=INFO source=types.go:130 msg="inference compute" id=GPU-e906b231-b215-914a-537f-6c2494cbf492 library=cuda variant=v12 compute=9.0 driver=12.7 name="NVIDIA H100" total="93.1 GiB" available="92.6 GiB"
slurmstepd: error: *** JOB 12483645 ON gcn126 CANCELLED AT 2025-06-18T23:13:36 ***
